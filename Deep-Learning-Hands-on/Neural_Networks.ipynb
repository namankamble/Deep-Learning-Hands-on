{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8465aaf-3cd9-4900-acd6-12cab2ac06b8",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Introducing Neural Networks***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef52234-5074-4c6b-854d-7923d87c053e",
   "metadata": {},
   "source": [
    "Neural networks, also called **Artificial Neural Networks** (though it seems, in recent years, we’ve dropped the **“artificial”** part), are a type of ***machine learning*** often conflated with ***deep learning***. The defining characteristic of a deep​ neural network is having two or more hidden layers a concept that will be explained shortly, but these hidden layers are ones that the neural network controls. It’s reasonably safe to say that most neural networks in use are a form of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ae9df-9130-4514-a63e-56e63d379768",
   "metadata": {},
   "source": [
    "***\n",
    "## ***A Brief History***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531d142-950e-4be4-90f2-bd466b65418f",
   "metadata": {},
   "source": [
    "Since the advent of computers, scientists have been formulating ways to enable machines to take input and produce desired output for tasks like **classification** and **regression** general, there’s **supervise** and **unsupervised**. Additionally, in machine learning. **Supervised machine** learning is used when you have pre-established and labeled data that can be used for training. suppose you have sensor data for a server with metrics such as upload/download rates, temperature, and humidity, all organized by time for every 10 minutes. Normally, this server operates as intended and has no outages, but sometimes parts fail and cause an outage. We might collect data and then divide it into two classes: one class for times/observations when the server is operating normally, and another class for times/observations when the server is experiencing an outage. When the server is failing, we want to label that sensor data leading up to failure as data that preceded a failure. When the server is operating normally, we simply label that data as “normal.” "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d959cb6-65a3-4ea0-b148-e7caacde365a",
   "metadata": {},
   "source": [
    "What each sensor measures in this example is called a **feature**. A group of features makes up a **feature set** (represented as vectors/arrays), and the values of a feature set can be referred to as a **sample**. Samples are fed into neural network models to train them to fit desired outputs from these inputs or to predict based on them during the inference phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d15c03-10b7-4bed-8c84-6c9c447bf3ae",
   "metadata": {},
   "source": [
    "**Neural networks** were conceived in the 1940s, but figuring out how to train them remained a mystery for 20 years. The concept of backpropagation (explained later) came in the 1960s, but neural networks still did not receive much attention until they started winning competitions in 2010. Since then, neural networks have been on a meteoric rise due to their sometimes seemingly magical ability to solve problems previously deemed unsolvable, such as **image captioning**, **language translation**, **udio** and **video synthesis**, and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a80f9b-217b-4bd7-9c71-35f02f81e9fc",
   "metadata": {},
   "source": [
    "Currently, **neural networks** are the primary solution to most competitions and challenging technological problems like **self-driving cars**, **calculating risk**, **detecting fraud**, and early cancer detection, to name a few."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66823d4d-b531-4cc8-9660-99a76a468698",
   "metadata": {},
   "source": [
    "***\n",
    "## ***What is a Neural Network?***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364c8bc-47b5-4af8-b44e-edc64656505c",
   "metadata": {},
   "source": [
    "**Artificial neural networks** are inspired by the organic brain, translated to the computer. It’s not a perfect comparison, but there are **neurons**, **activations**, and **lots of interconnectivity**, even if the underlying processes are quite different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689efb1-9b27-457a-b934-f40e40bffac3",
   "metadata": {},
   "source": [
    "A typical neural network has thousands or even up to millions of adjustable parameters **(weights and biases)**. In this way, neural networks act as enormous functions with vast numbers of parameters. The concept of a long function with millions of variables that could be used to solve a problem isn’t all too difficult. With that many variables related to neurons, arranged as interconnected layers, we can imagine there exist some combinations of values for these variables that will yield desired outputs. Finding that combination of parameter (weight and bias) values is the challenging part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffbb24-12b1-4581-a33c-5ff4765fff40",
   "metadata": {},
   "source": [
    "The end goal for neural networks is to adjust their **weights** and **biases** (the parameters), so when applied to a yet unseen example in the input, they produce the desired output. When supervised machine learning algorithms are trained, we show the algorithm examples of inputs and their associated desired outputs. One major issue with this concept is overfitting when the algorithm only learns to fit the training data but doesn’t actually “understand” anything about underlying input-output dependencies. The network basically just **memorizes** the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba184dd-0988-4003-8796-c0193cbfdc2b",
   "metadata": {},
   "source": [
    "Thus, we tend to use **in-sample** data to train a model and then use **out-of-sample** data to validate an algorithm (or a neural network model in our case). Certain percentages are set aside for both datasets to partition the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedb345-1547-48e5-9d47-63d53b5f0db5",
   "metadata": {},
   "source": [
    "For example: if there is a dataset of 100,000 samples of data and labels, you will immediately take 10,000 and set them aside to be your **out-of-sample** or **validation** data. You will then train your model with the other 90,000 in-sample or “training” data and finally validate your model with the 10,000 out-of-sample data that the model hasn’t yet seen. The goal is for the model to not only accurately predict on the training data, but also to be similarly accurate while predicting on the withheld out-of-sample validation data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
